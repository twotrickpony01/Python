import platform
from pathlib import Path
import datetime
import re
import sqlite3
import subprocess

## TODO ##
# Implement the file_types_to_check_list filter in get_all_files_by_mod_time()
# Integrate get_dates_in_range function and consider making it a passed object throughout the tool

# Make the tool accept arguments

# Write all of the results to a file

# Create an uncategorized files_modified / browser history function (and filter?)

# Add in screenshots take use OpenCV ? to guess what the tester was doing

# Consider some way to identify targets of actions. 
#   Would be difficult as it would require that we dig into the files

# Should create a setup script that adds this to a Windows / Linux scheduled task. Can use platform library for this
# # Test on Windows and Linux

## END TODO ##


### Helpers ###
def convert_to_epoch_time(datetime_object):
    epoch_start = datetime.datetime(1601, 1, 1, tzinfo=datetime.timezone.utc)
    # Convert datetime_object to utc
    datetime_object_converted_to_utc = datetime_object.replace(tzinfo=datetime.timezone.utc)
    time_difference = datetime_object_converted_to_utc - epoch_start
    seconds_in_a_day = 24 * 60 * 60
    time = (time_difference.microseconds + (time_difference.seconds + time_difference.days * seconds_in_a_day) * 10**6)
    return time

    
def convert_from_epoch_time(epoch_time, date_format):
    epoch_start = datetime.datetime(1601, 1, 1, tzinfo=datetime.timezone.utc)
    time = (epoch_start + datetime.timedelta(microseconds=int(epoch_time))).strftime(date_format)
    return time


def get_dates_in_range(start_date, end_date, date_format):
    # I think that there's an easier way to handle this in so many functions, but I'm not sure how
    # Pre-populate the dictionary with dates
    date_key_dict = {}
    for day in range(0, (end_date - start_date).days + 1):
        date = (start_date + datetime.timedelta(days=day)).strftime(date_format)
        date_key_dict[date] = []
    return date_key_dict

### Primary Functions ###
def identify_activities_by_name(file_name):
    # Use regex to map a string to an activity.
    # Can be file names, page titles, etc. 
    regex_to_activity_mapping_dictionary = {
        '.*burp.*': 'Evaluated <web_app> using BurpSuite.',
        '.*nmap.*':'Configured and ran Nmap scans.',
        '.*nessus.*':'Configured and ran Nessus scans.',
        '.*nikto.*': 'Configured and ran Nikto scans.'
    }
    
    # Not sure that this is necessary
    for key in regex_to_activity_mapping_dictionary:
        if re.search(key, file_name):
            return regex_to_activity_mapping_dictionary[key]
        else:
            return f"Uncategorized activity: {file_name}"


def get_all_files_by_mod_time(directory, start_date, end_date, date_format, file_types_to_check_list = ['xml']):
    # Check the modify / creation time of files on the OS and return them
    # file_types_to_check_list acts as a filter for which files to search for
    files_by_date_dict = {}
    
    # Pre-populate the dictionary with dates
    for day in range(0, (end_date - start_date).days + 1):
        date = (start_date + datetime.timedelta(days=day)).strftime(date_format)
        files_by_date_dict[date] = []

    # Get all of the files using pathlib and an rglob regex
    # Apparently calling stat().st_mtime on each file can be very slow, so just 
    # grab all files and filter them first so we can reduce the load
    files = [path for path in directory.rglob("*") if path.is_file()]
    
    # Check dates of files and add them to the files_by_date_dict (date:[list_of_file_names])
    for file in files:
        file_mod_date = datetime.datetime.fromtimestamp(file.stat().st_mtime)
        if start_date <= file_mod_date <= end_date:
            file_mod_date_formatted = file_mod_date.strftime(date_format)
            if files_by_date_dict[file_mod_date_formatted]:
                files_by_date_dict[file_mod_date_formatted].append(file._str) #._str attribute is string-ified filename
            else:
                files_by_date_dict[file_mod_date_formatted] = [file._str]
    
    return files_by_date_dict


def get_chrome_history(chrome_history_file_location, start_date, end_date, date_format):
    # TO DO 
    # Add in option to close / reopen Chrome
    # Integrate get_dates_in_range function
    # # files_by_date_dict = get_dates_in_range(start_date, end_date, date_format)
    files_by_date_dict = {}
    # Pre-populate the dictionary with dates
    for day in range(0, (end_date - start_date).days + 1):
        date = (start_date + datetime.timedelta(days=day)).strftime(date_format)
        files_by_date_dict[date] = [] 

    # Should add logic to ask users if we should be closing out chrome here

    sqlite_chrome_connection = sqlite3.connect(chrome_history_file_location)

    epoch_start_date = convert_to_epoch_time(start_date)
    epoch_end_date = convert_to_epoch_time(end_date)

    sql_statement = f"""
                SELECT title,last_visit_time FROM urls 
                WHERE last_visit_time > {epoch_start_date}
                AND last_visit_time < {epoch_end_date} 
                ORDER BY last_visit_time DESC;""" 

    pages_visited = sqlite_chrome_connection.execute(sql_statement).fetchall()
    for page in pages_visited:
        date = convert_from_epoch_time(page[1], date_format)
        if files_by_date_dict[date]:
                files_by_date_dict[date].append(page[0])
        else:
            files_by_date_dict[date] = [page[0]]

    sqlite_chrome_connection.close()

    # Re-open Chrome here.

    return files_by_date_dict    

def consolidate_dates_between_modules(list_of_dictionaries, start_date, end_date, date_format):
    # TO DO 
    # Integrate get_dates_in_range here ( or pass the dictionary / object for it )
    # # consolidated_dictionaries = get_dates_in_range(start_date, end_date, date_format)
    consolidated_dictionaries = {}
    # Pre-populate the dictionary with dates
    for day in range(0, (end_date - start_date).days + 1):
        date = (start_date + datetime.timedelta(days=day)).strftime(date_format)
        consolidated_dictionaries[date] = []

    for dictionary in list_of_dictionaries:
        tmp_dictionary = consolidated_dictionaries
        for date in dictionary:
            # Remove duplicates using list(dict.fromkeys()) trick
            old_and_new_values = list(dict.fromkeys(consolidated_dictionaries[date] + dictionary[date]))
            tmp_dictionary[date] = old_and_new_values
        consolidated_dictionaries = tmp_dictionary

    return consolidated_dictionaries

def timeline_file_generator(activity_by_date, timeline_file, output_mode = None):
    # TO DO
    # Allow for generation of HMTL elements if wanted
    with open(timeline_file, 'w+', encoding="utf-8") as timeline:
        for date in activity_by_date:
            timeline.write(f'{date}\n')
            for activity in activity_by_date[date]:
                if activity:
                    timeline.write(f'{activity}\n')
            timeline.write('\n')

def create_scheduled_task(operating_system):
    # Get this .py file's current location
    path_and_filename_of_program_to_be_run = None

    if operating_system == 'Windows':
        subprocess.call(f'schtasks /Create /sc weekly /D MON,TUE,WED,THU,FRI /st 18:00 /TR calculator.exe /TN Timeline_Generator') # replace calculator.exe with this script's location.
    elif operating_system == 'Linux':
        pass

def main():
    # TO DO 
    # Integrate create_scheduled_task
    # Integrate dynamic location of chrome history file
    
    # Configuration Details
    user_directory = str(Path.home())
    operating_system = platform.system()
    if operating_system == 'Windows':
        # 
        chrome_history_file = Path(f"{user_directory}/AppData/Local/Google/Chrome/User Data/Default/History")
    elif operating_system =='Linux':
        chrome_history_file = Path("")
    
    date_format = "%m/%d/%Y"
    file_types_to_check_list = []

    # directory variable is the directory (and its sub-directories) that will be searched for files.
    directory = Path(f"{user_directory}/Downloads/")

    # Location of the output file
    
    timeline_file = f"{user_directory}/Desktop/timeline_file.txt"

    start_date = datetime.datetime(2023, 12, 1)
    end_date = datetime.datetime(2023, 12, 12)
    # Create dictionary object with date_ranges here

    # Modules 
    files_by_date = get_all_files_by_mod_time(directory, start_date, end_date, date_format) 
    chrome_history = get_chrome_history(chrome_history_file, start_date, end_date, date_format)

    # Consolidate
    # Will this be necessary if we pass the dictionary of items by their date?
    consolidated_dictionaries = consolidate_dates_between_modules([files_by_date, chrome_history], start_date, end_date, date_format)
    
    timeline_file_generator(consolidated_dictionaries, timeline_file)


if __name__ == "__main__":
    main()